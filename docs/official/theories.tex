\section{Theories}
A theory with name \code{MyTheory} over a vocabulary \code{MyVoc} is declared by
\begin{lstlisting}
	theory MyTheory : MyVoc {
		// contents of the theory
	}
\end{lstlisting}
A theory contains sentences and inductive definitions.

\subsection{Sentences}


\subsubsection{Terms}

Before explaining the syntax for sentences, we need to introduce the concept of a term and a formula. We also give the syntax for terms and formulas in \idp.\\


A \emph{term} is inductively defined as follows:
\begin{itemize}
	\item a variable is a term;
	\item a constant is a term;
	\item if $F$ is a function symbol with $n$ input arguments and $t_1, \ldots, t_n$ are terms, then $F(t_1,\ldots,t_n)$ is a term. 
\end{itemize}
In \idp, variables start with a letter and may contain letters, digits and underscores. When writing a term in \idp, the constant and function symbols occurring in that term should be declared before. \\
The \emph{type of a term} is defined as its return type (see section~\ref{ssec:symbols}) in the case of constants and functions. The type of a variable is derived from its occurrences in formulas (see section~\ref{ssec:vtype}). If a term occurs in an input position of a function, then the type of the term and the type of the input position must have a common ancestor type. 

\subsubsection{Formulas and Sentences}

A \emph{formula} is inductively defined by:
\begin{itemize}
	\item \textbf{true} and \textbf{false} are formulas;
	\item if $P$ is a predicate symbol with arity $n$ and $t_1,\ldots,t_n$ are terms, then $P(t_1,\ldots,t_n)$ is a formula;
	\item if $t_1$ and $t_2$ are terms, then $t_1 = t_2$ is a formula;
	\item if $\varphi$ and $\psi$ are formulas and $x$ is a variable, then the following are formulas: $\lnot \varphi$, $\varphi \land \psi$, $\varphi \lor \psi$, $\varphi \limplies \psi$, $\varphi \limpliedby \psi$, $\varphi \lequiv \psi$, $\forall x\ \varphi$, and $\exists x\ \varphi$.
\end{itemize}
The following order of binding is used: $\lnot$ binds tightest, next $\land$, then $\lor$, then $\limpliedby$, followed by $\limplies$, then $\lequiv$, and finally $\forall$ and $\exists$. 
All operators are right associative, for example $P \limplies Q \limplies R$ is equivalent to the formula $P \limplies (Q \limplies R)$.
Disambiguation can be done using brackets `(' and `)'. E.g. the formula $\forall x\ P(x) \land \lnot Q(x) \limplies R(x)$ is equivalent to the formula $\forall x\ ((P(x) \land (\lnot Q(x))) \limplies R(x))$. 

As for terms, if term $t$ occurs in predicate $P$, then the type of $t$ and the type of the input position of $P$ where it occurs must have a common ancestor type. For formulas of the form $t_1 = t_2$, $t_1$ and $t_2$ must have a common ancestor type.


The \emph{scope} of a quantification $\forall x$ or $\exists x$, is the quantified formula. E.g., in $\forall x\ \psi$, the scope of $\forall x$ is the formula $\psi$. An occurrence of a variable $x$ that is not inside the scope of a quantification $\forall x$ or $\exists x$ is called \emph{free}. A \emph{sentence} is a formula containing no free occurrences of variables. If an \idp problem specification contains formulas that are not sentences, the system will implicitly quantify this variable universally and return a warning message, specifying which variables occur free. Each sentence in \idp ends with a dot `.'.

The \idp syntax of the different symbols in formulas are given in the table below. Also the informal meaning of the symbols is given.
\begin{center}
\begin{tabular}{c|c|l}
Logic & \idp & Declarative reading \\
\hline
$\land$		& \code{ \&}	& and \\
$\lor$		& \code{ |}	& or	\\
$\lnot$		& \code{$\sim$}	& not \\
$\limplies$		& \code{ =>}	& implies \\
$\limpliedby$		& \code{ <=}	& is implied by \\
$\lequiv$		& \code{ <=>}	& is equivalent to \\
$\forall$	& \code{ !}	& for each \\
$\exists$	& \code{ ?}	& there exists \\
$=$			& \code{ =}	& equals \\
$\neq$		& \code{$\sim$=}	& does not equal \\ 
\end{tabular}
\end{center}

Besides this, for every natural number $n$, \idp also supports the following quantifiers (with their respective meanings):

\begin{center}
\begin{tabular}{c|c|l}
\idp & Declarative reading \\
\hline
\code{?n}	& there exist exactly $n$ different elements such that \\
\code{?<n} & there exist less than $n$ \\
\code{?=<n} & there exist at most $n$\\
\code{?=n} & there exist exactly $n$ (this is the same as \code{?n})\\
\code{?>n} & there exist more than $n$
\end{tabular}
\end{center}

A universally quantified formula $\forall x\ P(x)$ becomes `{\tt !\,x\,:\,P(x)}' in \idp syntax, and similarly for existentially quantified formulas. As a shorthand for the formula `{\tt !\,x\,:\,!\,y\,:\,!\,z\,:\,Q(x,y,z).}', one can write `{\tt !\,x y z\,:\,Q(x,y,z)}'. 

\idp also supports binary quantifications, which allow to writer shorter or more readable formulas:
\begin{center}
\begin{tabular}{c|c|l}
Binary Quantification & Shorthand for \\
\hline
\code{? (x,y) in P : Q(x,y)}	&  \code{? x y : P(x,y) \& Q(x,y)} \\
\code{! (x,y) in P : Q(x,y)}	&  \code{! x y : P(x,y) => Q(x,y)} \\
\code{? (x,y) sat P(x,y) : Q(x,y)}	&  \code{? x y : P(x,y) \& Q(x,y)} \\
\code{! (x,y) sat P(x,y) : Q(x,y)}	&  \code{! x y : P(x,y) => Q(x,y)} \\
\end{tabular}
\end{center}

In \idp, every variable has a type. The informal meaning of a sentence of the form $\forall x\ \psi$, respectively $\exists x\ \psi$, where $x$ has type $T$ is then `for each object $x$ of type $T$, $\psi$ must be true', respectively `there exists at least one object $x$ of type $T$ such that $\psi$ is true'. The type of a variable can be declared by the user, or derived by \idp (see section~\ref{ssec:vtype}).


\subsubsection{Definitions}
A definition defines a concept, i.e. a predicate (or multiple predicates), in terms of other predicates. Formally, a definition is a set of rules of the form 
\[ \forall x_1,\ldots,x_n\ P(t_1,\ldots,t_m) \lrule \varphi \]
where $P$ is a predicate symbol, $t_1,\ldots,t_m$ are terms that may contain the variables $x_1,\ldots,x_n$ and $\varphi$ a formula that may contain these variables. $P(t_1,\ldots,t_m)$ is called the \emph{head} of the rule and $\psi$ the \emph{body}. 

A definition in \idp syntax consists of a set of rules, enclosed by `\code{\{}' and `\code{\}}'. Each rule ends with a `\code{.}'. The definitional implication $\lrule$ is written `\code{<-}'. The quantifications before the head may be omitted in \idp (\idp will give a warning in this case), i.e., all free variables of a rule are implicitly universally quantified. If the body of a rule is empty (\code{true}), the rule symbol `\code{<-}' can be omitted. Recursive definitions are allowed in \idp. The semantics for a definitions are the well-founded semantics \todo{reference}.
As an example, the following definition defines the transitive closure of a relation \code{R}.
\begin{lstlisting}
	{
		!x y: T(x,y) <- R(x,y).
		!x y: T(x,y) <- ?z: T(x,z) & T(z,y).
	}
\end{lstlisting}



\subsection{Chains of (in)equalities}
As in mathematics, one can write chains of (in)equalities in \idp. They can be used as shorthands for conjunctions of (in)equalities. E.g.:
\begin{lstlisting}
	! x y : (1 =< x < y =< 5) => ...
	// is a shorthand for
	! x y : ((1 =< x) & (x < y) & (y =< 5)) => ...
\end{lstlisting}

\subsection{Aggregates}
Aggregates are functions that take a set as argument, instead of a simple variable. \idp supports some aggregates that map a set to an integer. As such, they can be seen as integer terms.

Syntacticly, one writes sets in \idp in the following manner:
\begin{itemize}
	\item An expression of the form `{\tt \{ x\_1 x\_2 ... x\_n : phi : t\}}', where the {\tt x\_i} are variables, {\tt phi} is a formula and $t$ is a term. The variables \code{x\_i} can occur in both \code{phi} and \code{t}. %This denotes the set of all tuples  {\tt (a\_1,a\_2, ...,a\_n)} of objects such that {\tt phi} is true if each occurrence of an {\tt x\_i} in {\tt phi} is replaced by {\tt a\_i}. 
\end{itemize} 
The informal interpretation of sets is:
\begin{itemize}
 \item The multiset consisting of: for every tuple of domain elements \code{(a\_1,a\_2, ...,a\_n)},  the term \code{t[a\_i/x\_i]} if \code{phi[a\_i/x\_i]} is true.
\end{itemize}

The current system has support for five aggregate functions:
\begin{description}
	\item[Cardinality:] The cardinality of a set is the number of elements in that set. The \idp syntax for the cardinality of a set $S$ is `{\tt card} $S$' or `{\tt \#} $S$' and this denotes the number of tuples {\tt(a\_1,a\_2,..., a\_n)} such that {\tt phi} is true.
	\item[Sum:] Let $S$ be a set of the form, i.e., of the form `{\tt \{ x\_1 x\_2 ... x\_n : phi : t \}}'. Then the interpretation of `{\tt sum} $S$' denotes the number
	\[ \sum_{{\tt(a\_1,a\_2,..., a\_n)} | I\vDash {\tt phi}} {\tt t }, \]
	i.e., it is the sum of all the terms for which there exist {\tt a\_1,\ldots, a\_n} that make the formula {\tt phi} true. For sets of the first sort, this is interpreted as 
\[ \sum_{i | I\vDash {\tt phi\_i}} {\tt t_i }. \]
	\item[Product:] Products are defined similarly to sum.  The syntax for the product of \code{S} is \code{prod S}.
	\item[Maximum:] One can write `{\tt max} $S$' to denote the maximum value of the terms in $S$, i.e.,
	\[ \max_{{\tt(a\_1,a\_2,..., a\_n)} | I\vDash {\tt phi}} {\tt t} \] for sets of the second sort.  Sets of the first sort are handled analogously. %{\tt(a\_1,a\_2,..., a\_n)} \in S} {\tt a\_1 }, \]
	\item[Minimum:] To get the minimum value, write `{\tt min} $S$'.
\end{description}
When using cardinality, the terms do not matter.  You can choose to write $1$ for every term, but are also allowed to leave out the terms.
%{\color{Red}IMPORTANT NOTE}: At the moment, the solver cannot handle negative numbers in product aggregates.

\subsubsection{Aggregates on lists of terms}

Next to these aggregates that take a set as argument, \idp also supports lists of terms as a set. \idp supports four operations in this syntax: Sum, Max, Min and Prod.
A sum operation would look like this:
\[ sum(t_1,t_2,t_3,\ldots,t_n)\]
and is interpreted as \[\sum_{i=1..n} t_i\]
The three other operations are similar.

\subsubsection{Aggregates on lists of formulas}

For the fifth aggregate Card, \idp supports lists of formulas. 
A formula with cardinality aggregate on list looks like this: \[\forall \overline{x}:(\#(F_1(x),F_2(x),\ldots,F_k(x))=n)\]
This means that for every $\overline{x}$ exactly $n$ formulas in that list are true.
For example, \[\forall x[Figure]:(\#(Triangle(x),Square(x),Pentagon(x))=1)\] means that every figure is Triangle, Square or Pentagon, but never both or all three of them.

\subsection{Partial functions}\label{ssec:partial}
Normally, functions are total: they assign an output value to each of the input values. On the other hand, \emph{partial} functions do not necessarily have this property. In \idp, a partial function $F$ can arise in different situations. Either $F$ is explicitly declared as partial, or it is a built-in integer function (for example modulo).

The semantics of a partial function $F$ is given by transforming constraints and rules where $F$ occurs as follows:
\begin{itemize}
	\item in a \emph{positive} context, $P(\ldots,F(x),\ldots)$ is transformed to $\forall y\ (F(x) = y \limplies P(\ldots,y,\ldots))$;
	\item in a negative context, $P(\ldots,F(x),\ldots)$ is transformed to $\exists y\ (F(y) = y \land P(\ldots,y,\ldots))$.
\end{itemize}
Here, $P(\ldots,F(x),\ldots)$ occurs in a positive context if it occurs in sentence and in the scope of an even number of negations, or it occurs in a body of a rule and in the scope of an odd number of negations. All other occurrences are in a negative context. 

                                                              
\subsection{The Type of a Variable}\label{ssec:vtype}
There are two ways to assign a type $t$ to a variable $v$:
\begin{itemize}
	\item Explicitly mention the type of $v$ between `{\tt [}' and `{\tt ]}' when $v$ is quantified. Then $v$ gets type $t$ in the scope of the quantifier. E.g.,
	\begin{lstlisting}
	theory T: V {
		! MyVar[MyType] : ? MyVar2[MyType2] MyVar3[MyType3] : //...
	}
	\end{lstlisting}
	\item Do not mention the type of $v$ but let the system automatically derive it. The rest of this section explains how this is done.
\end{itemize}

\subsubsection{Automatic derivation of types for variables}



We distinguish between \emph{typed} and \emph{untyped} occurrences. The following are typed occurrences of a variable $x$:
\begin{itemize}
	\item an occurrence as argument of a non-overloaded predicate: $P(\ldots,x,\ldots)$;
	\item an occurrence as argument of a non-overloaded function: $F(\ldots,x,\ldots) = \ldots$;
	\item an occurrence as return value of a non-overloaded function: $F(\ldots) = x$ or $F(\ldots) \neq x$. 
\end{itemize}

All others positions are untyped. 

An overloaded predicate or function symbol can be disambiguated by specifying its vocabulary and/or types.  E.g.,
\begin{lstlisting}
	! x: MyVoc::P[A,A](x,x).
	! y: ?1 x : F[A:A](x) = y.
	MyVoc::C[:A] > 2.
\end{lstlisting}
In this case, the occurrences of all variables are typed.


Basically, if a variable occurs in one typed position, it gets the type of that position.  
If a declared variable with type \code{T\_1} occurs in a typed position of type \code{T\_2}, then \code{T\_1} and \code{T\_2} should have a common ancestor type.


The more complicated cases arise when a variable does not occur in any typed position, or it occurs in two typed positions with a different type. The system is designed to give a reasonable type to such variables. However, the choices made by the system might be ad hoc or not the ones the user intended, hence, every time \idp derives a type, it will give a warning, including which type it derived for the variable. 

First consider the case where a variable occurs in typed positions with different types. If all the typed positions where the variable occurs have a common ancestor type $T$, then the variable is assigned the least common ancestor of those types. If they do not have a common ancestor, no derivation is done.

Now consider the case where a variable does not occur in a typed position. Then, the \idp system tries to find out what the type of the variable should be using its occurrences in untyped positions in built-in overloaded functions.  For example, when a variable $x$ only occurs in $x=t$, then $x$ will get the same type as $t$.   It's always safer to declare a type for the variable in this case.  If it is not possible to derive a type for $x$ in this way either, the \idp system reports an error.

